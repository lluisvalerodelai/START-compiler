#include "lexer.h"
#include <cstdio>
#include <fstream>
#include <iostream>

// return number of tokens generated by lexer()
int count_tokens(Token *tokens_list) {
  int count = 0;
  while (tokens_list[count].type != END) {
    count++;
  }
  return count;
}

int main(int argc, char *argv[]) {

  char *fname = argv[1];
  FILE *fptr = std::fopen(fname, "r");
  Token *tokens = lexer(fptr);

  if (fptr == NULL) {
    perror("ERROR: File does not exist");
    return 1;
  }

  int count = count_tokens(tokens);
  for (int i = 0; i < count + 1; i++) {
    std::cout << tokens[i].value << "\n";
  }

  fclose(fptr);

  return 0;
}
