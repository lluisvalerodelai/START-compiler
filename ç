#include "lexerpp.hpp"

using std::string;

void pretty_print_tokens(std::vector<Token> tokens) {
  for (int i = 0; i < tokens.size(); i++) {
    Token tokens_i = tokens[i];
    std::cout << "Token " << i << ": " << tokens_i.type;
    std::cout << " value: "<< tokens_i.value << std::endl;
  }
}

std::vector<Token> lexer(std::ifstream &F) {
  char c;
  bool are_checking_string = false;

  std::vector<Token> token_list;
  token_list.reserve(100);
  // main loop

  while (!F.eof()) {
    c = F.get();

    // check if its a skippable char
    if (!are_checking_string) {
      switch (c) {
      case '\b':
        continue;
      case '\f':
        continue;
      case '\n':
        continue;
      case ' ':
        continue;
      case '\t':
        continue;
      case '\e':
        continue;
      }
    }

    // check if its a separator

    if (c == '{') {
      Token separator_token{.type = token_type::keyword, .value = "{"};
      token_list.emplace_back(separator_token);
    } else if (c == '}') {
      Token separator_token{.type = token_type::separator, .value = "}"};
      token_list.emplace_back(separator_token);
    } else if (c == '(') {
      Token separator_token{.type = token_type::separator, .value = "("};
      token_list.emplace_back(separator_token);
    } else if (c == ')') {
      Token separator_token{.type = token_type::separator, .value = ")"};

      token_list.emplace_back(separator_token);
    } else if (c == '[') {
      Token separator_token{.type = token_type::separator, .value = "["};

      token_list.emplace_back(separator_token);
    } else if (c == ']') {
      Token separator_token{.type = token_type::separator, .value = "]"};

      token_list.emplace_back(separator_token);
    } else if (c == ';') {
      Token separator_token{.type = token_type::separator, .value = ";"};
      token_list.emplace_back(separator_token);
    } else if (c == '=') {

      //check if next char is a =, in which case the token is ==

      char next_char = F.peek();

        if (next_char == '='){
          Token separator_token{.type = token_type::operator_token, .value = "=="};
          token_list.emplace_back(separator_token);
          //move ahead by 2 to get to the next whitespace so we dont read the next = on the next cycle
          c = F.get();
          c = F.get();
        }else{
          Token separator_token{.type = token_type::operator_token, .value = "="};
          token_list.emplace_back(separator_token);
        }

    } else if (c == '+') {
      
        char next_char = F.peek();

        if (next_char == '='){
            Token separator_token{.type = token_type::operator_token, .value = "+="};
            token_list.emplace_back(separator_token);
            //move ahead by 2 to get to the next whitespace so we dont read the next = on the next cycle
            c = F.get();
            c = F.get();
          }else{
            Token separator_token{.type = token_type::separator, .value = "+"};
            token_list.emplace_back(separator_token);
          }

    } else if (c == '-') {
        char next_char = F.peek();

          if (next_char == '='){
              Token separator_token{.type = token_type::operator_token, .value = "-="};
              token_list.emplace_back(separator_token);
              //move ahead by 2 to get to the next whitespace so we dont read the next = on the next cycle
              c = F.get();
              c = F.get();
            }else{
              Token separator_token{.type = token_type::separator, .value = "-"};
              token_list.emplace_back(separator_token);
            }

    } else if (c == '*') {
        char next_char = F.peek();

          if (next_char == '='){
              Token separator_token{.type = token_type::operator_token, .value = "*="};
              token_list.emplace_back(separator_token);
              //move ahead by 2 to get to the next whitespace so we dont read the next = on the next cycle
              c = F.get();
              c = F.get();
            }else{
              Token separator_token{.type = token_type::separator, .value = "*"};
              token_list.emplace_back(separator_token);
            }
    } else if (c == '/') {
      // check if the next one isnt /, in which case add a comment token and go to start of next line
      char next_c = F.get();
      if (next_c == '/'){
        //consume the next /
        c = F.get();
        //consume chars until we hit a line break char
        while (c != '\n'){
          c = F.get();
        }
        //first consume the last eol char, and check for \r\n eols
        if (c == '\n'){
          c = F.get();
        }
      }else if (next_c == '*'){
        //consume next char
        c = F.get();
        c = F.get();
        while (c != '*' && !F.eof()){
            c = F.get(); 
        }
        //we are at C = *, move to next char which will be /
        c = F.get();
      }else {
          // if its none of those, add a / token
          Token separator_token{.type = token_type::operator_token, .value = "/"};
          token_list.emplace_back(separator_token);
      } 
    // check if its a number,
    } else if ((isdigit(c) != 0)){
      std::string number = "";
      number += c;
      //is the current char a number?, then add it to the list and move on to the next and repeat
      char next_c = F.peek(); 
      while (isdigit(next_c)){
        c = F.get();
        number += c;
        next_c = F.peek();
        if (!isdigit(F.peek())) {
          break; 
        }
      }

      Token numeric{.type = token_type::operator_token, .value = number }; 
      token_list.emplace_back(numeric);


    // for as long as the char were on is a number, add it to the buffer, unless
    // its a . if its a . we check if we have already added a . before and if
    // not then we add it

    // check for a string, when we see a ", fill up the buffer until the next ".
    // turn off checks for ignorable characters
    //
    //  if its none of the above, then its either a keyword or an identifier, in
    //  which case we fill up the buffer for as long as were in an alphanum
    //  character until we see skippable chars
  }

  //add end token
  Token end_token{.type = token_type::END, .value = "END"};
  token_list.emplace_back(end_token);
  return token_list;
}

int main(int argc, char **argv) {

  string file_name = argv[1];

  std::ifstream fileObject{file_name};

  std::vector<Token> tokens = lexer(fileObject);
  pretty_print_tokens(tokens);
  return 0;
}
