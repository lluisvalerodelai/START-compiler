#include "lexerpp.hpp"
#include <cstdio>
#include <iostream>
#include <stack>
#include <string>
#include <vector>

class Lang {
public:
  std::vector<Token> tokens;
  int line_nr = 0;
  bool buffer_occupied = false;
  std::stack<Token> token_wait_area;
  std::stack<Token> inline_tokens;

  Lang(std::vector<Token> toks) {
    for (int i = toks.size() - 1; i >= 0; i--) {
      inline_tokens.push(toks[i]);
    }
  }

  void stack_collapse() {
    while (!token_wait_area.empty()) {
      Token top_token = token_wait_area.top();
      token_wait_area.pop();
      inline_tokens.push(top_token);
    }
  }

  void __raiseError(std::string message) {
    throw std::invalid_argument("ERROR line " + std::to_string(line_nr) + ": " +
                                message);
  }

  Token next_token() {
    if (!token_wait_area.empty()) {

      Token top_token = token_wait_area.top();
      token_wait_area.pop();
      return top_token;

    } else {

      if (inline_tokens.empty()) {
        throw std::runtime_error("inline_tokens are empty");
      }

      Token top_token = inline_tokens.top();
      inline_tokens.pop();
      return top_token;
    }
  };

  void return_token(Token token) { token_wait_area.push(token); }

  void print_inline_tokens() {
    std::cout << "wait area tokens: \n";
    while (!token_wait_area.empty()) {
      std::cout << token_wait_area.top().value << ", ";
      token_wait_area.pop();
    }
    std::cout << " \n inline tokens: \n";
    while (!inline_tokens.empty()) {
      std::cout << inline_tokens.top().value << ", ";
      inline_tokens.pop();
    }
    std::cout << std::endl;
  }

  bool parse_statement() {
    if (!parse_print_statement()) { // for now the only statement is a print
      return false;
    }
    return true;
  }

  bool parse_print_statement() {
    Token token_next = next_token();
    inline_tokens.push(token_next);
    if (token_next.value != "print") {
      stack_collapse();
      return false;
    }
    token_next = next_token();
    inline_tokens.push(token_next);
    if (token_next.value != "(") {
      stack_collapse();
      return false;
    }
    if (!parse_literal_type()) { // if we succesfully parsed a literal, then its
      return false;              // contents will be on the wait stack
    }
    token_nex

        return true;
  }

  bool parse_literal_type() {
    if (next_token().type != token_type::literal) {
      __raiseError("expected literal");
    }
    return true;
  }
};

// return number of tokens generated by lexer()
int count_tokens(Token *tokens_list) {
  int count = 0;
  while (tokens_list[count].type != END) {
    count++;
  }
  return count;
}

int main(int argc, char **argv) {

  std::string file_name = argv[1];

  std::ifstream fileObject{file_name};

  std::vector<Token> tokens = lexer(fileObject);

  Lang e(tokens);
  std::cout << e.parse_statement();

  return 0;
}
