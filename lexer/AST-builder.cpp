#include "lexerpp.hpp"
#include <cstdio>
#include <iostream>
#include <stack>
#include <string>
#include <vector>

class Lang {
public:
  std::vector<Token> tokens;
  int line_nr = 0;
  bool buffer_occupied = false;
  std::stack<Token> token_wait_area;
  std::stack<Token> inline_tokens;
  std::vector<std::string> errors;

  Lang(std::vector<Token> toks) {
    toks.erase(toks.end() - 2);
    for (int i = toks.size() - 1; i >= 0; i--) {
      inline_tokens.push(toks[i]);
    }
  }

  void stack_collapse() {
    std::cout << "STACK COLLAPSE" << "\n";
    while (!token_wait_area.empty()) {
      Token top_token = token_wait_area.top();
      token_wait_area.pop();
      inline_tokens.push(top_token);
    }
  }

  void clear_stack() {
    while (!token_wait_area.empty()) {
      token_wait_area.pop();
    }
  }

  void add_error(std::string message) {
    errors.emplace_back("ERROR line " + std::to_string(line_nr) + ": " +
                        message);
  }

  Token next_token() {
    if (inline_tokens.empty()) {
      throw std::runtime_error("inline_tokens are empty");
    }

    Token top_token = inline_tokens.top();
    inline_tokens.pop();
    return top_token;
  };

  void return_token(Token token) { token_wait_area.push(token); }

  void print_inline_tokens() {
    std::cout << "wait area tokens: \n";
    while (!token_wait_area.empty()) {
      std::cout << token_wait_area.top().value << ", ";
      token_wait_area.pop();
    }
    std::cout << " \n inline tokens: \n";
    while (!inline_tokens.empty()) {
      std::cout << inline_tokens.top().value << ", ";
      inline_tokens.pop();
    }
    std::cout << std::endl;
  }

  bool parse_program() {
    if (!parse_statement()) {
      return false;
    }
    while (inline_tokens.top().value != "END") {
      if (!parse_statement()) {
        return false;
      }
    }
    return true;
  }

  bool parse_statement() {
    if (!parse_dec_ass() && !parse_print_statement()) {
      return false;
    }
    if (!parse_semicolon()) {
      return false;
    }
    clear_stack(); // need to clear stack again after checking for semicolon
                   // since we dont take care of it in previous functs
    return true;
  }

  bool parse_semicolon() {
    Token token_next = next_token();
    token_wait_area.push(token_next);
    if (token_next.value != ";") {
      stack_collapse();
      return false;
    }
    return true;
  }

  bool parse_print_statement() {
    Token token_next = next_token();
    token_wait_area.push(token_next);
    if (token_next.value != "print") {
      stack_collapse();
      return false;
    }
    token_next = next_token();
    token_wait_area.push(token_next);
    if (token_next.value != "(") {
      stack_collapse();
      return false;
    }
    if (!parse_expression()) {
      return false;
    }
    token_next = next_token();
    token_wait_area.push(token_next);
    if (token_next.value != ")") {
      stack_collapse();
      return false;
    }
    clear_stack();
    return true;
  }

  bool parse_dec_ass() {
    Token token_next = next_token();
    token_wait_area.push(token_next);

    if (token_next.value != "int") {
      stack_collapse();
      return false;
    }
    token_next = next_token();
    token_wait_area.push(token_next);
    if (token_next.type != token_type::identifier) {
      stack_collapse();
      return false;
    }
    token_next = next_token();
    token_wait_area.push(token_next);
    if (token_next.value != "=") {
      stack_collapse();
      return false;
    }
    token_next = next_token();
    token_wait_area.push(token_next);
    if (token_next.type != token_type::literal) {
      stack_collapse();
      return false;
    }
    clear_stack();
    return true;
  }

  bool parse_expression() {
    Token token_next = next_token();
    token_wait_area.push(token_next);
    if (token_next.type != token_type::literal) {
      stack_collapse();
      return false;
    }
    return true;
  }
};

// return number of tokens generated by lexer()
int count_tokens(Token *tokens_list) {
  int count = 0;
  while (tokens_list[count].type != END) {
    count++;
  }
  return count;
}

int main(int argc, char **argv) {

  std::string file_name = argv[1];

  std::ifstream fileObject{file_name};

  std::vector<Token> tokens = lexer(fileObject);

  Lang e(tokens);
  bool result = e.parse_program();

  if (result) {
    std::cout << "compilation completed succesfully \n";
  } else {
    std::cout << "compilation failed \n";
  }

  return 0;
}
